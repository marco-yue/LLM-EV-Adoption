{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54269607-0ca2-4525-b5b1-05f851eb859b",
   "metadata": {},
   "source": [
    "### 01 packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6feabbc0-4829-46b9-ab5c-6d4c35ececea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4cb4d8-b917-41bb-b64b-259bb45f7fbf",
   "metadata": {},
   "source": [
    "### 02 rule-based cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fde4e4-6396-468d-9e91-428eb33256d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews:  5923\n",
      "Filtered reviews:  4258\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "output_dir = \"02data\"\n",
    "input_file = os.path.join(output_dir, \"user_reviews.csv\")\n",
    "\n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "df=pd.read_csv(input_file)\n",
    "\n",
    "###################################################################################################################\n",
    "###################################################################################################################\n",
    "\n",
    "# ------------------- Preprocessing -------------------\n",
    "\n",
    "# Create a new column 'description_clean' that:\n",
    "# 1. Converts the 'description' column to string\n",
    "# 2. Converts all text to lowercase (for case-insensitive matching)\n",
    "df['description_clean'] = df['description'].astype(str).str.lower()\n",
    "\n",
    "# Calculate the length of each description; could be used to filter very short (likely uninformative) texts.\n",
    "df['description_length'] = df['description_clean'].str.len()\n",
    "\n",
    "# ------------------- Filtering -------------------\n",
    "\n",
    "# Define a set of keywords that are likely to indicate the review is related to a car purchase or review.\n",
    "# You can expand or adjust this list depending on your needs.\n",
    "filter_keywords = [\n",
    "    \"bought\",              # common verb for purchase\n",
    "    \"purchased\",           # alternative verb\n",
    "    \"got\",                 # sometimes used casually\n",
    "    \"buy\",                 # generic purchase verb (e.g., \"buying a car\")\n",
    "    \"car review\",          # directly indicates a review\n",
    "    \"my new car\",          # ownership confirmation\n",
    "    \"car purchase\",        # indicates a purchase experience\n",
    "    \"review\"               # generic review keyword (may add noise, adjust as needed)\n",
    "]\n",
    "\n",
    "# Define a helper function that checks whether a given text contains any of the keywords.\n",
    "def contains_keyword(text, keywords):\n",
    "    for kw in keywords:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "# Apply the filtering function to create a boolean column 'relevant'\n",
    "df['relevant'] = df['description_clean'].apply(lambda x: contains_keyword(x, filter_keywords))\n",
    "\n",
    "# Select only the rows that are marked as relevant (i.e., contain at least one keyword)\n",
    "filtered_df = df[df['relevant'] == True].copy()\n",
    "\n",
    "# ------------------- Output -------------------\n",
    "\n",
    "# Show the number of total reviews and how many passed the filter\n",
    "print(\"Total reviews: \", len(df))\n",
    "print(\"Filtered reviews: \", len(filtered_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc1efa-0a10-4cf1-93b4-b3691c169836",
   "metadata": {},
   "source": [
    "### 03 LLM-based cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9a220-b402-407c-8a67-c16554f252ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Configuration ----------------------\n",
    "with open(\"secret.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read().strip()  # Read the ChatGPT API key\n",
    "\n",
    "# ---------------------- Define LLM Analysis Function ----------------------\n",
    "\n",
    "def remove_markdown_formatting(text):\n",
    "    \"\"\"\n",
    "    Removes markdown code block markers from a string.\n",
    "    If the text starts with ``` (possibly followed by a language tag)\n",
    "    and ends with ```, remove those lines.\n",
    "    \"\"\"\n",
    "    lines = text.strip().splitlines()\n",
    "    if lines and lines[0].startswith(\"```\"):\n",
    "        # Remove the first line (opening marker) and the last line if it contains ```\n",
    "        lines = lines[1:]\n",
    "        if lines and lines[-1].strip().startswith(\"```\"):\n",
    "            lines = lines[:-1]\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "def analyze_review(description):\n",
    "    \"\"\"\n",
    "    Uses the OpenAI ChatCompletion API to analyze a car review description.\n",
    "    The prompt instructs the model to carefully read the review text and extract:\n",
    "      1. has_car: \"Yes\" if the review clearly states that the user bought or owns a car; \"No\" otherwise.\n",
    "      2. car_model: The exact car model mentioned (e.g., \"Tesla Model 3\", \"BMW 3 Series\");\n",
    "         return an empty string if none is clearly mentioned.\n",
    "      3. fuel_type: \"Electric\" if the review indicates an electric vehicle,\n",
    "         \"Conventional\" if it indicates a fuel-based vehicle, or \"Unknown\" if it cannot be determined.\n",
    "    \n",
    "    Args:\n",
    "        description (str): The review text.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with keys \"has_car\", \"car_model\", and \"fuel_type\" if successful;\n",
    "              otherwise, returns None.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert automobile analyst. Carefully read the following review text and answer the following three questions:\n",
    "1. Does the review clearly state that this user bought or owns a car? Answer \"Yes\" or \"No\".\n",
    "2. If yes, what is the exact car model mentioned? (For example, \"Tesla Model 3\", \"BMW 3 Series\"). If none is clearly mentioned, return an empty string.\n",
    "3. Based on the review text, determine whether the car is Electric or Conventional. Answer \"Electric\" if it is an electric vehicle, \"Conventional\" if it is a fuel-based vehicle, or \"Unknown\" if it cannot be determined.\n",
    "Return your answer strictly in JSON format with exactly the keys: \"has_car\", \"car_model\", \"fuel_type\".\n",
    "\n",
    "Review text:\n",
    "\\\"\\\"\\\"{description}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Change to \"gpt-4\" if available and desired.\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=400,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        raw_output = response.choices[0].message.content.strip()\n",
    "        raw_output=remove_markdown_formatting(raw_output)\n",
    "        # Parse the output as JSON\n",
    "        result = json.loads(raw_output)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing description: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------------------- Process Each Filtered Review with Progress Bar ----------------------\n",
    "results = []  # This list will hold the structured LLM analysis results.\n",
    "\n",
    "# Use tqdm to display a progress bar during iteration.\n",
    "for idx, row in tqdm(filtered_df.iterrows(), total=len(filtered_df), desc=\"Processing reviews\"):\n",
    "    description = row.get(\"description\", \"\")\n",
    "    user_id = row.get(\"user_id\", \"Unknown\")\n",
    "    \n",
    "    analysis = analyze_review(description)\n",
    "    if analysis:\n",
    "        # Save the extracted fields and include original context fields.\n",
    "        analysis[\"user_id\"] = user_id\n",
    "        analysis[\"comment_time\"] = row.get(\"comment_time\", \"\")\n",
    "        results.append(analysis)\n",
    "    else:\n",
    "        print(f\"Skipping row {idx} due to analysis error.\")\n",
    "    \n",
    "    # Optional: Add a short delay to manage API rate limits.\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# ---------------------- Save Final Results to CSV ----------------------\n",
    "# Convert the results list into a DataFrame.\n",
    "results_df = pd.DataFrame(results)\n",
    "# Ensure that the output DataFrame contains the desired columns.\n",
    "desired_cols = [\"user_id\", \"comment_time\", \"has_car\", \"car_model\", \"fuel_type\"]\n",
    "results_df = results_df[[col for col in desired_cols if col in results_df.columns]]\n",
    "\n",
    "output_file = os.path.join(output_dir, \"filtered_user_reviews.csv\")\n",
    "results_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"LLM analysis complete. {len(results_df)} records saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
